\documentclass[10pt]{article}

\usepackage[a4paper, margin=0.8in]{geometry}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{booktabs}
\usepackage{titlesec}
\usepackage{enumitem}
\usepackage{hyperref}

\titlespacing*{\section}{0pt}{6pt}{4pt}
\setlist[itemize]{noitemsep, topsep=2pt}

\title{\vspace{-1cm}CW1 Regression Challenge}
\author{
Kasim Morsel \\
K24060083 \\
\vspace{4pt}
\small \url{https://github.com/KasimM05/Kasim-5CCSAMLF-CW}
}
\date{\vspace{-0.8cm}}

\begin{document}
\maketitle
\vspace{-0.8cm}

\section{Introduction}
This report summarises a reproducible tabular regression pipeline for predicting \texttt{outcome}. The dataset contains 10,000 training rows and a separate held-out test set with hidden labels. Since test labels are unavailable, model development is based on 5-fold cross-validation (CV) on the training data. The final deliverable is a one-column submission file (\texttt{yhat}) generated from a fixed model configuration.

\section{Exploratory Data Analysis}
The training data has 31 columns: 27 numerical predictors, 3 categorical predictors (\texttt{cut}, \texttt{color}, \texttt{clarity}), and 1 target column (\texttt{outcome}). No missing values were detected in the provided training file.

Figure~\ref{fig:target} shows the target distribution. The outcome is roughly bell-shaped with visible tails, so methods that can model nonlinearity are appropriate.

\begin{figure}[!ht]
\centering
\includegraphics[width=0.45\linewidth]{figures/target_dist.png}
\caption{Distribution of target variable \texttt{outcome}.}
\label{fig:target}
\end{figure}

Figure~\ref{fig:corr} shows substantial correlation among size-related variables (\texttt{carat}, \texttt{x}, \texttt{y}, \texttt{z}) and structure inside engineered blocks (\texttt{a1--a10}, \texttt{b1--b10}). This supports using flexible nonlinear models rather than purely linear assumptions.

\begin{figure}[!ht]
\centering
\includegraphics[width=0.55\linewidth]{figures/corr_heatmap.png}
\caption{Correlation heatmap of numerical predictors.}
\label{fig:corr}
\end{figure}

All preprocessing was implemented inside an sklearn \texttt{Pipeline}/\texttt{ColumnTransformer} to avoid leakage during CV:
\begin{itemize}
    \item Numerical: median imputation.
    \item Categorical: most-frequent imputation, then ordinal encoding with unknown categories mapped to \texttt{-1}.
\end{itemize}
Although no missing values were observed, imputers were kept for robustness and reproducibility.

\section{Model Selection}
Model comparison was performed with identical preprocessing and 5-fold CV. Three model families were compared:
\begin{itemize}
    \item Ridge regression (linear baseline),
    \item Random Forest Regressor (bagged trees),
    \item Histogram Gradient Boosting Regressor (boosted trees).
\end{itemize}

Table~\ref{tab:comparison} reports mean and standard deviation for CV $R^2$ and RMSE.

\begin{table}[!ht]
\centering
\small
\begin{tabular}{lcccc}
\toprule
Model & CV $R^2$ mean & CV $R^2$ std & CV RMSE mean & CV RMSE std \\
\midrule
HistGradientBoosting & 0.4560 & 0.0217 & 9.3780 & 0.1743 \\
RandomForest & 0.4545 & 0.0200 & 9.3905 & 0.1350 \\
Ridge & 0.2844 & 0.0159 & 10.7583 & 0.1475 \\
\bottomrule
\end{tabular}
\caption{Cross-validated model comparison (5-fold, identical preprocessing).}
\label{tab:comparison}
\end{table}

HistGradientBoosting achieved the best overall performance and was selected for final training/submission.

\section{Model Training and Evaluation}
The final submission model is \texttt{HistGradientBoostingRegressor} with fixed parameters:
\begin{itemize}
    \item \texttt{learning\_rate}=0.039,
    \item \texttt{max\_iter}=300,
    \item \texttt{max\_depth}=3,
    \item \texttt{max\_leaf\_nodes}=255,
    \item \texttt{min\_samples\_leaf}=10,
    \item \texttt{l2\_regularization}=1.0.
\end{itemize}

Using the same 5-fold CV protocol, this final configuration achieved:
\[
\text{CV Mean } R^2 = 0.4718, \quad \text{CV Std } R^2 = 0.0210.
\]
The model was then retrained on all training rows and used to predict the held-out test set.

\section{Code Supplement}
Repository link (implementation and reproducibility):
\[
\url{https://github.com/KasimM05/Kasim-5CCSAMLF-CW}
\]

Main commands:
\begin{verbatim}
python compare_models.py
python build_submission.py
\end{verbatim}

Outputs:
\begin{itemize}
    \item \texttt{submissions/model\_comparison.csv} (model selection evidence),
    \item \texttt{submissions/CW1\_submission\_K24060083.csv} (final test predictions).
\end{itemize}

\section{Conclusion}
A leakage-safe pipeline was used for preprocessing, model comparison, and final training. Direct CV comparison across model families showed boosted trees performed best. The fixed-parameter HistGradientBoosting model achieved stable CV performance (\(R^2 \approx 0.472\)) and was selected for submission.

\end{document}

